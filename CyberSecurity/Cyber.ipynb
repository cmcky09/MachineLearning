{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f2ce801",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './TrafficLabelling/Dataset1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c3c7ee64c549>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mDataset_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./TrafficLabelling/Dataset1.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mDataset_1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './TrafficLabelling/Dataset1.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Dataset_1 = pd.read_csv(\"./TrafficLabelling/Dataset1.csv\")\n",
    "Dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a18f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(Dataset_1)\n",
    "#Dataset_1[' Label'].nunique()\n",
    "#assert(Dataset_1[' Label'].nunique()>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(Dataset_1[' Label'].nunique()>1)\n",
    "Dataset_1[' Label'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5863cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Dataset_1['Flow ID'].nunique())\n",
    "print(Dataset_1[' Source IP'].nunique())\n",
    "print(Dataset_1[' Source Port'].nunique())\n",
    "print(Dataset_1[' Destination IP'].nunique())\n",
    "print(Dataset_1[' Destination Port'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c394d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1019ba96",
   "metadata": {},
   "source": [
    "Q3:\n",
    "Considering that we have the ground truth, we are trying to predict a target variable on a finite dataset, and we don't have an environment, I choose supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df14aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_1[' Label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db404f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_1[' Label'].replace(['BENIGN', 'FTP-Patator', 'SSH-Patator'],[0,1,1],inplace=True)\n",
    "print(Dataset_1[' Label'].unique())\n",
    "Dataset_1[' Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffb2997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q4\n",
    "print(\"Balance:\")\n",
    "print(Dataset_1[Dataset_1[' Label']==0][' Label'].count(), \"Benign\")\n",
    "print(Dataset_1[Dataset_1[' Label']==1][' Label'].count(), \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1358c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#most important port numbers for security\n",
    "#https://cowbell.insure/blog/port-security-1/\n",
    "\"\"\"15 Netstat\n",
    "20/21 FTP\n",
    "23 Telnet\n",
    "25 SMTP\n",
    "50/51 IPSec\n",
    "53 DNS\n",
    "67/68 BOOTP\n",
    "69 TFTP\n",
    "79/49 TACACS+\n",
    "80 HTTP\n",
    "88 Kerberos\n",
    "110 POP3\n",
    "111 Port Map\n",
    "119 NNTP\n",
    "123 NTP\n",
    "137-139 NetBIOS\n",
    "143 IMAP\n",
    "161 SNMP\n",
    "389 LDAP\n",
    "445 SMB\n",
    "500 IPSec/ISAKMP\n",
    "520 RIP\n",
    "546/547 DHCP\n",
    "636 SLDAP\n",
    "1512 WINS\n",
    "1701 L2TP\n",
    "1720 323\n",
    "1723 PPTP\n",
    "1812/13 RADIUS\n",
    "3389 RDP\n",
    "5004/5005 RTP\n",
    "5060/5061 SIP\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d29009",
   "metadata": {},
   "outputs": [],
   "source": [
    "strs = r\"\"\"15 Netstat\n",
    "20\n",
    "21 FTP\n",
    "23 Telnet\n",
    "25 SMTP\n",
    "50\n",
    "51 IPSec\n",
    "53 DNS\n",
    "67\n",
    "68 BOOTP\n",
    "69 TFTP\n",
    "79\n",
    "49 TACACS+\n",
    "80 HTTP\n",
    "88 Kerberos\n",
    "110 POP3\n",
    "111 Port Map\n",
    "119 NNTP\n",
    "123 NTP\n",
    "137\n",
    "138\n",
    "139 NetBIOS\n",
    "143 IMAP\n",
    "161 SNMP\n",
    "389 LDAP\n",
    "445 SMB\n",
    "500 IPSec/ISAKMP\n",
    "520 RIP\n",
    "546\n",
    "547 DHCP\n",
    "636 SLDAP\n",
    "1512 WINS\n",
    "1701 L2TP\n",
    "1720 323\n",
    "1723 PPTP\n",
    "1812\n",
    "13 RADIUS\n",
    "3389 RDP\n",
    "5004\n",
    "5005 RTP\n",
    "5060\n",
    "5061 SIP\"\"\"\n",
    "l =strs.split()\n",
    "nums = []\n",
    "for s in l:\n",
    "    try:\n",
    "        nums.append(int(s))\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "print(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92666513",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_sources = {a:[] for a in nums}\n",
    "dfs_dests = {a:[] for a in nums}\n",
    "dfs_sources['other_ports'] = []\n",
    "dfs_dests['other_ports'] = []\n",
    "for i in range(len(Dataset_1)):\n",
    "    if Dataset_1[' Source Port'][i] in nums:\n",
    "        dfs_sources['other_ports'].append(0)\n",
    "    else:\n",
    "        dfs_sources['other_ports'].append(1)\n",
    "    if Dataset_1[' Destination Port'][i] in nums:\n",
    "        dfs_dests['other_ports'].append(0)\n",
    "    else:\n",
    "        dfs_dests['other_ports'].append(1)\n",
    "        \n",
    "    for k in dfs_sources.keys():\n",
    "        if k == 'other_ports':\n",
    "            continue\n",
    "        if Dataset_1[' Source Port'][i]==k:\n",
    "            dfs_sources[k].append(1)\n",
    "        else:\n",
    "            dfs_sources[k].append(0)\n",
    "        if Dataset_1[' Destination Port'][i]==k:\n",
    "            dfs_dests[k].append(1)\n",
    "        else:\n",
    "            dfs_dests[k].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcb1890",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfs_dests[50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c678e645",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in dfs_sources.keys():\n",
    "    df = pd.DataFrame(dfs_sources[k],columns=['source port '+str(k)])\n",
    "    Dataset_1= Dataset_1.join(df)\n",
    "    df = pd.DataFrame(dfs_dests[k],columns=[' Destination Port'+str(k)])\n",
    "    Dataset_1= Dataset_1.join(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aec24b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_1.drop(' Source Port',axis = 1, inplace=True)\n",
    "Dataset_1.drop(' Destination Port',axis = 1, inplace=True)\n",
    "Dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8dbae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import plot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {x : Dataset_1[(Dataset_1[' Label']==1) & (Dataset_1[' Flow Duration'] == x)][' Label'].count()\\\n",
    "     for x in Dataset_1[' Flow Duration'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f59772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04340f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so most cyberattacks occur below 276 flow duration\n",
    "x = []\n",
    "y = []\n",
    "for k in sorted(d.keys()):\n",
    "    x.append(k)\n",
    "    y.append(d[k])\n",
    "    if(d[k]>10):\n",
    "        print(k)\n",
    "plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce829f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {x : Dataset_1[(Dataset_1[' Label']==1) & (Dataset_1['Flow Bytes/s'] == x)][' Label'].count()\\\n",
    "     for x in Dataset_1['Flow Bytes/s'].unique()}\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70888159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#\n",
    "x = []\n",
    "y = []\n",
    "for k in sorted(d.keys()):\n",
    "    x.append(k)\n",
    "    y.append(d[k])\n",
    "    if(d[k]>100):\n",
    "        print(k)\n",
    "    \n",
    "plot(x,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a2bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = list(Dataset_1[' Timestamp'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14a908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd2e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "times = []\n",
    "for i in range(len(t)):\n",
    "    date_time = t[i].split()\n",
    "    print(date_time)\n",
    "    time = date_time[1]\n",
    "    hour_min = time.split(':')\n",
    "    hour_min[0] = int(hour_min[0])\n",
    "    if hour_min[1] == '00':\n",
    "        hour_min[1] = 0\n",
    "    hour_min[1] = int(hour_min[1])\n",
    "\n",
    "    if int(hour_min[0]) < 8:\n",
    "        hour_min[0] = int(hour_min[0])+12\n",
    "    times.append(int(hour_min[1]) + hour_min[0]*60)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5afcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dataset_1.drop([' Timestamp'],axis=1,inplace=True)\n",
    "Dataset_1 = Dataset_1.join(pd.DataFrame(times, columns=['Timestamp']))\n",
    "Dataset_1\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d624aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36086dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_1.drop('Flow ID',axis=1,inplace=True)# Flow ID is derived from source and destination IPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d32ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset_1[' Timestamp'] = pd.to_datetime(Dataset_1[' Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c2fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_1.drop(' Timestamp',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8353cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset_1[\" Source IP\"]=Dataset_1[\" Source IP\"].apply(str)\n",
    "#Dataset_1[\" Destination IP\"]=Dataset_1[\" Destination IP\"].apply(str)\n",
    "Dataset_1.drop(' Source IP',axis=1,inplace=True)\n",
    "Dataset_1.drop(' Destination IP',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0892824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdd16f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nanList = []\n",
    "for name in list(Dataset_1):\n",
    "    if Dataset_1[name].isnull().values.any():\n",
    "        nanList.append(name)\n",
    "nanList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f2b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_1['Flow Bytes/s'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcccf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_1.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d1429",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3da68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_1['Flow Bytes/s'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c66b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1004906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Dataset_1[' Label']\n",
    "X = Dataset_1.drop(' Label',axis=1,inplace=False)#didn't lose too much data, less than .1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c1e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59643aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cross_val_score(clf, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5348a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp =MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbea0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(mlp, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "s = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65abd451",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(s, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6457bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q8\n",
    "def function(filepath, clf,clustering = False):\n",
    "    import pandas as pd\n",
    "\n",
    "    Dataset_1 = pd.read_csv(filepath)\n",
    "    Dataset_1\n",
    "\n",
    "    list(Dataset_1)\n",
    "    #Dataset_1[' Label'].nunique()\n",
    "    #assert(Dataset_1[' Label'].nunique()>1)\n",
    "\n",
    "    \n",
    "    Dataset_1[' Label'].nunique()\n",
    "\n",
    "    print(Dataset_1['Flow ID'].nunique())\n",
    "    print(Dataset_1[' Source IP'].nunique())\n",
    "    print(Dataset_1[' Source Port'].nunique())\n",
    "    print(Dataset_1[' Destination IP'].nunique())\n",
    "    print(Dataset_1[' Destination Port'].nunique())\n",
    "\n",
    "\n",
    "\n",
    "    Dataset_1[' Label'].unique()\n",
    "\n",
    "    Dataset_1[' Label'].replace(['BENIGN', 'FTP-Patator', 'SSH-Patator'],[0,1,1],inplace=True)\n",
    "    print(Dataset_1[' Label'].unique())\n",
    "    Dataset_1[' Label']\n",
    "\n",
    "    #q4\n",
    "    print(\"Balance:\")\n",
    "    print(Dataset_1[Dataset_1[' Label']==0][' Label'].count(), \"Benign\")\n",
    "    print(Dataset_1[Dataset_1[' Label']==1][' Label'].count(), \"Other\")\n",
    "\n",
    "    \n",
    "\n",
    "    strs = r\"\"\"15 Netstat\n",
    "    20\n",
    "    21 FTP\n",
    "    23 Telnet\n",
    "    25 SMTP\n",
    "    50\n",
    "    51 IPSec\n",
    "    53 DNS\n",
    "    67\n",
    "    68 BOOTP\n",
    "    69 TFTP\n",
    "    79\n",
    "    49 TACACS+\n",
    "    80 HTTP\n",
    "    88 Kerberos\n",
    "    110 POP3\n",
    "    111 Port Map\n",
    "    119 NNTP\n",
    "    123 NTP\n",
    "    137\n",
    "    138\n",
    "    139 NetBIOS\n",
    "    143 IMAP\n",
    "    161 SNMP\n",
    "    389 LDAP\n",
    "    445 SMB\n",
    "    500 IPSec/ISAKMP\n",
    "    520 RIP\n",
    "    546\n",
    "    547 DHCP\n",
    "    636 SLDAP\n",
    "    1512 WINS\n",
    "    1701 L2TP\n",
    "    1720 323\n",
    "    1723 PPTP\n",
    "    1812\n",
    "    13 RADIUS\n",
    "    3389 RDP\n",
    "    5004\n",
    "    5005 RTP\n",
    "    5060\n",
    "    5061 SIP\"\"\"\n",
    "    l =strs.split()\n",
    "    nums = []\n",
    "    for s in l:\n",
    "        try:\n",
    "            nums.append(int(s))\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    print(nums)\n",
    "\n",
    "    dfs_sources = {a:[] for a in nums}\n",
    "    dfs_dests = {a:[] for a in nums}\n",
    "    dfs_sources['other_ports'] = []\n",
    "    dfs_dests['other_ports'] = []\n",
    "    for i in range(len(Dataset_1)):\n",
    "        if Dataset_1[' Source Port'][i] in nums:\n",
    "            dfs_sources['other_ports'].append(0)\n",
    "        else:\n",
    "            dfs_sources['other_ports'].append(1)\n",
    "        if Dataset_1[' Destination Port'][i] in nums:\n",
    "            dfs_dests['other_ports'].append(0)\n",
    "        else:\n",
    "            dfs_dests['other_ports'].append(1)\n",
    "\n",
    "        for k in dfs_sources.keys():\n",
    "            if k == 'other_ports':\n",
    "                continue\n",
    "            if Dataset_1[' Source Port'][i]==k:\n",
    "                dfs_sources[k].append(1)\n",
    "            else:\n",
    "                dfs_sources[k].append(0)\n",
    "            if Dataset_1[' Destination Port'][i]==k:\n",
    "                dfs_dests[k].append(1)\n",
    "            else:\n",
    "                dfs_dests[k].append(0)\n",
    "\n",
    "    print(len(dfs_dests[50]))\n",
    "\n",
    "    for k in dfs_sources.keys():\n",
    "        df = pd.DataFrame(dfs_sources[k],columns=['source port '+str(k)])\n",
    "        Dataset_1= Dataset_1.join(df)\n",
    "        df = pd.DataFrame(dfs_dests[k],columns=[' Destination Port'+str(k)])\n",
    "        Dataset_1= Dataset_1.join(df)\n",
    "\n",
    "    Dataset_1.drop(' Source Port',axis = 1, inplace=True)\n",
    "    Dataset_1.drop(' Destination Port',axis = 1, inplace=True)\n",
    "    Dataset_1\n",
    "\n",
    "    from matplotlib.pyplot import plot\n",
    "    import numpy as np\n",
    "\n",
    "    d = {x : Dataset_1[(Dataset_1[' Label']==1) & (Dataset_1[' Flow Duration'] == x)][' Label'].count()\\\n",
    "         for x in Dataset_1[' Flow Duration'].unique()}\n",
    "\n",
    "    d\n",
    "    if not clustering:\n",
    "\n",
    "        #so most cyberattacks occur below 276 flow duration\n",
    "        x = []\n",
    "        y = []\n",
    "        for k in sorted(d.keys()):\n",
    "            x.append(k)\n",
    "            y.append(d[k])\n",
    "            if(d[k]>10):\n",
    "                print(k)\n",
    "        plot(x,y)\n",
    "\n",
    "        d = {x : Dataset_1[(Dataset_1[' Label']==1) & (Dataset_1['Flow Bytes/s'] == x)][' Label'].count()\\\n",
    "             for x in Dataset_1['Flow Bytes/s'].unique()}\n",
    "\n",
    "        d\n",
    "\n",
    "\n",
    "\n",
    "        #\n",
    "        x = []\n",
    "        y = []\n",
    "        for k in sorted(d.keys()):\n",
    "            x.append(k)\n",
    "            y.append(d[k])\n",
    "            if(d[k]>100):\n",
    "                print(k)\n",
    "\n",
    "        plot(x,y)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    Dataset_1.drop('Flow ID',axis=1,inplace=True)# Flow ID is derived from source and destination IPs\n",
    "\n",
    "    #Dataset_1[' Timestamp'] = pd.to_datetime(Dataset_1[' Timestamp'])\n",
    "\n",
    "    Dataset_1.drop(' Timestamp',axis=1,inplace=True)\n",
    "\n",
    "    #Dataset_1[\" Source IP\"]=Dataset_1[\" Source IP\"].apply(str)\n",
    "    #Dataset_1[\" Destination IP\"]=Dataset_1[\" Destination IP\"].apply(str)\n",
    "    Dataset_1.drop(' Source IP',axis=1,inplace=True)\n",
    "    Dataset_1.drop(' Destination IP',axis=1,inplace=True)\n",
    "\n",
    "    Dataset_1\n",
    "\n",
    "    nanList = []\n",
    "    for name in list(Dataset_1):\n",
    "        if Dataset_1[name].isnull().values.any():\n",
    "            nanList.append(name)\n",
    "    nanList\n",
    "\n",
    "\n",
    "    Dataset_1['Flow Bytes/s'].isnull().sum()\n",
    "\n",
    "    Dataset_1.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    Dataset_1.dropna(inplace=True)#didn't lose too much data, less than .1%\n",
    "\n",
    "    Dataset_1['Flow Bytes/s'].isnull().sum()\n",
    "    \n",
    "    if not clustering:\n",
    "        y = Dataset_1[' Label']\n",
    "        X = Dataset_1.drop(' Label',axis=1,inplace=False)\n",
    "        print(cross_val_score(clf, X, y, cv=10))\n",
    "    else:\n",
    "        clf.fit(Dataset_1)\n",
    "        print(clf.cluster_centers_)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22634441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q9\n",
    "for i in range(1,8):\n",
    "    print(\"dataset\",i)\n",
    "    path = f\"./TrafficLabelling/Dataset{i:d}.csv\"#renamed all the files\n",
    "    function(path,DecisionTreeClassifier(random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb08a97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering for the one with all benign\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a54ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./TrafficLabelling/DatasetMonday.csv\"\n",
    "km = KMeans(n_clusters=3)\n",
    "function(path,km,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc5681",
   "metadata": {},
   "source": [
    "Q10\n",
    "Even with knowing practically nothing about cybersecurity, I can say that the vast majority of cyberattacks occur with minimal flow duration and flow bytes, although I have no idea what those are.  I would be interested in what an expert has to say about attacks with 0 flow bytes.  It is good to do at least a little research to make the models more effective.  Decision tree gets 99% accuracy.  I wonder if a subject matter expert could beat that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
