{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6149898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3916\n",
      "114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['class',\n",
       " 'cap-shape',\n",
       " 'cap-surface',\n",
       " 'cap-color',\n",
       " 'bruises',\n",
       " 'odor',\n",
       " 'gill-attachment',\n",
       " 'gill-spacing',\n",
       " 'gill-size',\n",
       " 'gill-color',\n",
       " 'stalk-shape',\n",
       " 'stalk-root',\n",
       " 'stalk-surface-above-ring',\n",
       " 'stalk-surface-below-ring',\n",
       " 'stalk-color-above-ring',\n",
       " 'stalk-color-below-ring',\n",
       " 'veil-type',\n",
       " 'veil-color',\n",
       " 'ring-number',\n",
       " 'ring-type',\n",
       " 'spore-print-color',\n",
       " 'population',\n",
       " 'habitat']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('mushroom_dataset.csv')\n",
    "print(len(df[df['class']=='p']))\n",
    "df\n",
    "names = list(df)\n",
    "k = 1\n",
    "for name in names:\n",
    "    if df[name].nunique()!=2:\n",
    "        k+= (df[name].nunique())\n",
    "    else:\n",
    "        k+=1\n",
    "print(k)\n",
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f10374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_onehot(_df, _f):\n",
    "    _df2 = pd.get_dummies(_df[_f], prefix='', prefix_sep='').groupby(level=0, axis=1).max().add_prefix(_f+' - ')\n",
    "    _df3 = pd.concat([_df, _df2], axis=1)\n",
    "    _df3 = _df3.drop([_f], axis=1)\n",
    "    return _df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b9e8a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>bruises</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>cap-shape - b</th>\n",
       "      <th>cap-shape - c</th>\n",
       "      <th>cap-shape - f</th>\n",
       "      <th>cap-shape - k</th>\n",
       "      <th>...</th>\n",
       "      <th>population - s</th>\n",
       "      <th>population - v</th>\n",
       "      <th>population - y</th>\n",
       "      <th>habitat - d</th>\n",
       "      <th>habitat - g</th>\n",
       "      <th>habitat - l</th>\n",
       "      <th>habitat - m</th>\n",
       "      <th>habitat - p</th>\n",
       "      <th>habitat - u</th>\n",
       "      <th>habitat - w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8124 rows Ã— 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class  bruises  gill-attachment  gill-spacing  gill-size  stalk-shape  \\\n",
       "0         0        0                0             0          0            0   \n",
       "1         1        0                0             0          1            0   \n",
       "2         1        0                0             0          1            0   \n",
       "3         0        0                0             0          0            0   \n",
       "4         1        1                0             1          1            1   \n",
       "...     ...      ...              ...           ...        ...          ...   \n",
       "8119      1        1                1             0          1            0   \n",
       "8120      1        1                1             0          1            0   \n",
       "8121      1        1                1             0          1            0   \n",
       "8122      0        1                0             0          0            1   \n",
       "8123      1        1                1             0          1            0   \n",
       "\n",
       "      cap-shape - b  cap-shape - c  cap-shape - f  cap-shape - k  ...  \\\n",
       "0                 0              0              0              0  ...   \n",
       "1                 0              0              0              0  ...   \n",
       "2                 1              0              0              0  ...   \n",
       "3                 0              0              0              0  ...   \n",
       "4                 0              0              0              0  ...   \n",
       "...             ...            ...            ...            ...  ...   \n",
       "8119              0              0              0              1  ...   \n",
       "8120              0              0              0              0  ...   \n",
       "8121              0              0              1              0  ...   \n",
       "8122              0              0              0              1  ...   \n",
       "8123              0              0              0              0  ...   \n",
       "\n",
       "      population - s  population - v  population - y  habitat - d  \\\n",
       "0                  1               0               0            0   \n",
       "1                  0               0               0            0   \n",
       "2                  0               0               0            0   \n",
       "3                  1               0               0            0   \n",
       "4                  0               0               0            0   \n",
       "...              ...             ...             ...          ...   \n",
       "8119               0               0               0            0   \n",
       "8120               0               1               0            0   \n",
       "8121               0               0               0            0   \n",
       "8122               0               1               0            0   \n",
       "8123               0               0               0            0   \n",
       "\n",
       "      habitat - g  habitat - l  habitat - m  habitat - p  habitat - u  \\\n",
       "0               0            0            0            0            1   \n",
       "1               1            0            0            0            0   \n",
       "2               0            0            1            0            0   \n",
       "3               0            0            0            0            1   \n",
       "4               1            0            0            0            0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "8119            0            1            0            0            0   \n",
       "8120            0            1            0            0            0   \n",
       "8121            0            1            0            0            0   \n",
       "8122            0            1            0            0            0   \n",
       "8123            0            1            0            0            0   \n",
       "\n",
       "      habitat - w  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "8119            0  \n",
       "8120            0  \n",
       "8121            0  \n",
       "8122            0  \n",
       "8123            0  \n",
       "\n",
       "[8124 rows x 113 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = list(df)\n",
    "for name in names:#automating binary replacements\n",
    "    if df[name].nunique()==2:\n",
    "        df[name].replace([df[name].unique()[0],df[name].unique()[1]],[0,1],inplace=True)\n",
    "    else:\n",
    "        pass\n",
    "        #df = encode_onehot(df,name)\n",
    "for name in names:#automating binary replacements\n",
    "    if df[name].nunique()!=2:\n",
    "        df = encode_onehot(df,name)\n",
    "    else:\n",
    "        pass\n",
    "        #df = encode_onehot(df,name)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afbb7526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=8124, M=112\n"
     ]
    }
   ],
   "source": [
    "#y = df['class']\n",
    "#X = df.drop('class',axis=1)\n",
    "\n",
    "dfX = df.loc[:, df.columns != 'class']\n",
    "dfy = df.loc[:, df.columns == 'class'].values.ravel()\n",
    "\n",
    "# Sanity check\n",
    "print(f'N={len(dfX)}, M={len(dfX.columns)}')\n",
    "X = dfX.values\n",
    "y = dfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c603f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-1688ea86cb03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_column_transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_column_selector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 10-fold CV evaluation of a classifier\n",
    "def eval_classifier(_clf, _X, _y):\n",
    "    accuracies = []\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
    "    for train_index, test_index in kf.split(_X, _y):\n",
    "        _clf.fit(_X[train_index], _y[train_index])\n",
    "        y_pred = _clf.predict(_X[test_index])\n",
    "        accuracies += [accuracy_score(_y[test_index], y_pred)]\n",
    "    return np.array(accuracies)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f80d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = eval_classifier(GaussianNB(), X, y)\n",
    "print(f'Naive Bayes CV accuracy={np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35260572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear', probability=True)\n",
    "acc = eval_classifier(svc, X, y)\n",
    "print(f'SVC accuracy={np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c1650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "acc = eval_classifier(mlp, X, y)\n",
    "print(f'MLP accuracy={np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5982554",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "acc = eval_classifier(dtc, X, y)\n",
    "print(f'Decision tree accuracy={np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dcb817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "acc = eval_classifier(rfc, X, y)\n",
    "print(f'Random Forest accuracy={np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d043ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use _m features randomly selected from _M features\n",
    "# a total of n_estimators many weak learners\n",
    "def features_randomsubset(_M, _m, n_estimators=1):\n",
    "    from numpy.random import choice\n",
    "    # returns a list of list of column choices - subset features\n",
    "    return [choice(_M, _m, replace=False) for _ in range(n_estimators)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcf4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_singleweak(_X, _y, _niters, _nfeatures):\n",
    "    accuracies = []\n",
    "    for _ in range(_niters):\n",
    "        # Keep the subset features (i.e. columns) the same for a 10-fold\n",
    "        cols = features_randomsubset(_X.shape[1], _nfeatures, n_estimators=1)\n",
    "        # 10-fold CV\n",
    "        kf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
    "        for train_index, test_index in kf.split(_X, _y):\n",
    "            clf = weakNB_fit(cols[0], _X[train_index], _y[train_index])\n",
    "            y_pred, y_prob = weakNB_predict(clf, cols[0], _X[test_index])\n",
    "            accuracies += [accuracy_score(_y[test_index], y_pred)]\n",
    "    return np.array(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa1ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6679d53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_ensemble(_X, _y, _niter, _n_estimators, _nfeatures):\n",
    "    accuracies = []\n",
    "    single_accuracy = []\n",
    "    for _ in range(_niter):\n",
    "        # Keep subset features, columns same for a 10-fold\n",
    "        cols = features_randomsubset(_X.shape[1], _nfeatures, n_estimators=_n_estimators)\n",
    "        # 10-fold CV\n",
    "        kf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
    "        for train_index, test_index in kf.split(_X, _y):\n",
    "            e_clf = ensembleNB_fit(cols, _X[train_index], _y[train_index])\n",
    "            y_pred = ensembleNB_predict(e_clf, cols, _X[test_index])\n",
    "            single_y_pred = e_clf[0].fit(_X[train_index], _y[train_index]).predict(_X[test_index])\n",
    "            accuracies += [accuracy_score(_y[test_index], y_pred)]\n",
    "            single_accuracy += [accuracy_score(_y[test_index], single_y_pred)]\n",
    "    return np.array(accuracies),np.array(single_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615c458c",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.unique(y, return_counts=True)\n",
    "NBpriors = [counts[1][0]/len(y), counts[1][1]/len(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554a6a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc68621d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876ff143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2242a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = .1,stratify=y)\n",
    "#random.sample(sorted(X_train),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5fc23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WEAK = 100\n",
    "def eval_single_weak(_X, _y, _niters, _nfeatures,classifier):\n",
    "    accuracies = []\n",
    "    for _ in range(_niters):\n",
    "        # Keep the subset features (i.e. columns) the same for a 10-fold\n",
    "        cols = features_randomsubset(_X.shape[1], _nfeatures, n_estimators=1)\n",
    "        # 10-fold CV\n",
    "        kf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
    "        for train_index, test_index in kf.split(_X, _y):\n",
    "            clf = classifier.fit(_X[train_index], _y[train_index])\n",
    "            y_pred = classifier.predict(_X[test_index])\n",
    "            accuracies += [accuracy_score(_y[test_index], y_pred)]\n",
    "    return np.array(accuracies)\n",
    "\n",
    "gaussian_ensemble = []\n",
    "svc_ensemble = []\n",
    "mlp_ensemble = []\n",
    "decision_tree_ensemble = []\n",
    "ensembles = [gaussian_ensemble,svc_ensemble,mlp_ensemble,decision_tree_ensemble]\n",
    "names = ['gaussian','svc','mlp','decision tree']\n",
    "for i in range(NUM_WEAK):\n",
    "    gaussian_ensemble.append(GaussianNB())\n",
    "    svc_ensemble.append(SVC(kernel='linear',probability =True))\n",
    "    mlp_ensemble.append(MLPClassifier(hidden_layer_sizes=(5, 2),max_iter=30,tol = 1e-1))\n",
    "    decision_tree_ensemble.append(DecisionTreeClassifier(max_depth=5,max_features=5))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7213c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ensembles)):\n",
    "    acc = eval_single_weak(X,y,10,5,ensembles[i][0])\n",
    "    print(f'First {names[i]:s} learners average Acc= {np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7820bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "l = [[1,2,3],[12,4,5],[1,2],[1]]\n",
    "random.sample(l,2)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec779891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = .1,stratify=y)\n",
    "def ensemble_fit(X_train,y_train,ensemble,subsample_ratio = .1):\n",
    "    X_train_copy = list(deepcopy(X_train))\n",
    "    y_train_copy = deepcopy(y_train)\n",
    "    #joined = pd.concat(pd.DataFrame(y_train_copy),(pd.DataFrame(X_train_copy)))\n",
    "    joined = []\n",
    "    for i in range(len(X_train_copy)):\n",
    "        joined.append(np.append(X_train_copy[i],y_train_copy[i]))\n",
    "    #print(len(joined[0]))\n",
    "    \n",
    "    for i in range(len(ensemble)):#ensuring each weak classifier gets at least 1 feature\n",
    "        s = random.sample(joined,int(subsample_ratio*len(X_train)))\n",
    "        new_y = []\n",
    "        #s=s.tolist()\n",
    "        for k in range(len(s)):\n",
    "            s[k] = s[k].tolist()\n",
    "        #print(s)\n",
    "        t =pd.DataFrame(s)\n",
    "        \"\"\"\n",
    "        for j in range(len(s)):\n",
    "            new_y.append(s[j][-1])\n",
    "            \n",
    "            s[j] = s[:len(s[j])-1]\n",
    "            #s[j] = np.array(s[j][0],dtype='float')\n",
    "            #print(len(s[j]))\n",
    "        print(len(s[1]))\n",
    "        #s = pd.DataFrame({i:list(s[j][i] for j in range(len(s))) for i in range(len(s[0]))}).values\n",
    "        d = defaultdict(lambda:[])\n",
    "        for k in range(len(s)):\n",
    "            for j in s[k]:\n",
    "                d[k].append(j)\n",
    "            \n",
    "        new_y=pd.DataFrame({0:new_y}).values.ravel()\n",
    "        \"\"\"\n",
    "        #print(s)\n",
    "        dfX = t.loc[:, [x for x in range(len(s[0])-1)]]\n",
    "        dfy = t.loc[:, len(s[0])-1].values.ravel()\n",
    "        X = dfX.values\n",
    "        y = dfy\n",
    "        #print(len(y))\n",
    "        #X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0)\n",
    "        #print(len(s[0]),len(s[1]),len(s[2]))\n",
    "        ensemble[i].fit(X,y)\n",
    "    \n",
    "\n",
    "for e in ensembles:\n",
    "    ensemble_fit(X_train,y_train,e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e93efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(X_test,ensemble):\n",
    "    predictions = []\n",
    "    for i in ensemble:\n",
    "        #subset = pd.DataFrame(X_test).iloc[:,[k for k in sorted(i[1])]]\n",
    "        predictions.append(i.predict(X_test))\n",
    "        \n",
    "    vote = []\n",
    "    #print(len(predictions))\n",
    "    for i in range(len(predictions[0])):\n",
    "        count_0 = 0\n",
    "        count_1 = 0\n",
    "        for j in range(len(predictions)):#sorry for not using np.argmax\n",
    "            if predictions[j][i]==0:\n",
    "                count_0+=1\n",
    "            else:\n",
    "                count_1+=1\n",
    "        if count_0>=count_1:#0 is poisonous, so >=\n",
    "            vote.append(0)\n",
    "        else:\n",
    "            vote.append(1)\n",
    "    return vote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36619015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109362bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ensembles)):\n",
    "    y_pred = ensemble_predict(X_test,ensembles[i])\n",
    "    acc = [accuracy_score(y_test, y_pred)]\n",
    "    print(f'Ensemble {names[i]:s} average Acc= {np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2768a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ratios = [0.005, 0.01, 0.03, 0.05, 0.1]\n",
    "#ratios = [0.001]+ratios #these ratios are so small they cause an issue with getting enough classes\n",
    "#ratios = [0.0005]+ratios\n",
    "\n",
    "\n",
    "def eval_ensemble(_X, _y,ensemble,subsample_ratio):\n",
    "    accuracies = []\n",
    "\n",
    "    # 10-fold CV\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=False, random_state=None)\n",
    "    for train_index, test_index in kf.split(_X, _y):\n",
    "        \n",
    "        ensemble_fit(_X[train_index],_y[train_index],ensemble,subsample_ratio = subsample_ratio)\n",
    "        y_pred = ensemble_predict(_X[test_index],ensemble)\n",
    "        accuracies += [accuracy_score(_y[test_index], y_pred)]\n",
    "\n",
    "    return np.array(accuracies)\n",
    "\n",
    "ensembles.append([DecisionTreeClassifier()])\n",
    "ensembles.append([GaussianNB()])\n",
    "ensembles.append([SVC(kernel='linear',probability =True)])\n",
    "ensembles.append([MLPClassifier()])\n",
    "names.append('single decision tree')\n",
    "names.append('single Gaussian NB')\n",
    "names.append('single SVC')\n",
    "names.append('single MLP')\n",
    "print(len(ensembles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56821bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_stats=[[[],[],[]] for i in range(len(ensembles))]\n",
    "for j in ratios:\n",
    "    print()\n",
    "    print()\n",
    "    print(f'For the subsample ratio {j:.5f}:')\n",
    "    print()\n",
    "    for i in range(len(ensembles)):\n",
    "    \n",
    "        acc = eval_ensemble(X, y,ensembles[i],subsample_ratio=j)\n",
    "        print(f'Ensemble {names[i]:s} average Acc= {np.mean(acc):.2f} {chr(177)}{np.std(acc):.3f}')\n",
    "        ensemble_stats[i][0].append(j)\n",
    "        ensemble_stats[i][1].append(np.mean(acc))\n",
    "        ensemble_stats[i][2].append(np.std(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a078901a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d38680",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(ensembles)):\n",
    "    plt.plot(ensemble_stats[i][0], ensemble_stats[i][1], label=names[i])\n",
    "    #plt.fill_between(ensemble_stats[i][0], ensemble_stats[i][1]-ensemble_stats[i][2], ensemble_stats[i][1]-ensemble_stats[i][2], alpha=0.5)\n",
    "plt.xlabel('Data Subset ratio')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
